{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from math import sqrt\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('./DATA/exported_data.csv')\n",
    "X = data.drop('取引価格（総額）', axis=1)\n",
    "y = data['取引価格（総額）']\n",
    "\n",
    "# 标准化数据\n",
    "X_scaler = StandardScaler()\n",
    "X_scaled = X_scaler.fit_transform(X)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_scaled = y_scaler.fit_transform(np.array(y).reshape(-1, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_estimators': 3000,\n",
    "    'learning_rate': 0.04,\n",
    "    'max_depth': 8,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'verbosity': 2, \n",
    "    'eval_metric': ['rmse', 'mae']  \n",
    "}\n",
    "\n",
    "current_time = datetime.now().strftime(\"%m-%d_%H:%M\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"xgboost_{current_time}\"):\n",
    "    xgb_model = xgb.XGBRegressor(**params)\n",
    "    \n",
    "    # 记录训练过程中的指标\n",
    "    eval_results = {}\n",
    "    xgb_model.fit(X_train, y_train, \n",
    "                  eval_set=[(X_train, y_train), (X_test, y_test)], \n",
    "                  verbose=True)\n",
    "    \n",
    "    # 提取训练过程中的指标\n",
    "    results = xgb_model.evals_result()\n",
    "    train_rmse = results['validation_0']['rmse']\n",
    "    train_mae = results['validation_0']['mae']\n",
    "    test_rmse = results['validation_1']['rmse']\n",
    "    test_mae = results['validation_1']['mae']\n",
    "    \n",
    "    # 获取最后一个迭代的指标\n",
    "    final_train_rmse = train_rmse[-1]\n",
    "    final_train_mae = train_mae[-1]\n",
    "    final_test_rmse = test_rmse[-1]\n",
    "    final_test_mae = test_mae[-1]\n",
    "    #预测并计算test指标\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.sklearn.log_model(xgb_model, \"model\")\n",
    "    mlflow.log_params(params)\n",
    "    # 记录最后一轮迭代的训练指标到 MLflow\n",
    "    mlflow.log_metric(\"final_train_rmse\", final_train_rmse)\n",
    "    mlflow.log_metric(\"final_train_mae\", final_train_mae)\n",
    "    mlflow.log_metric(\"final_test_rmse\", final_test_rmse)\n",
    "    mlflow.log_metric(\"final_test_mae\", final_test_mae)\n",
    "    \n",
    "    #\n",
    "    # y_pred = xgb_model.predict(X_test)\n",
    "    # mse = mean_squared_error(y_test, y_pred)\n",
    "    # rmse = sqrt(mse)\n",
    "print(f\"Test MSE: {mse}\")\n",
    "print(f\"Test RMSE: {rmse}\")\n",
    "print(f\"Test R²: {r2}\")\n",
    "print(f\"Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from math import sqrt\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('./DATA/exported_data.csv')\n",
    "X = data.drop('取引価格（総額）', axis=1)\n",
    "y = data['取引価格（総額）']\n",
    "\n",
    "# 标准化数据\n",
    "X_scaler = StandardScaler()\n",
    "X_scaled = X_scaler.fit_transform(X)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_scaled = y_scaler.fit_transform(np.array(y).reshape(-1, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_estimators': 3000,\n",
    "    'learning_rate': 0.04,\n",
    "    'max_depth': 8,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'verbosity': 2  # 将日志详细程度设置为 1\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    xgb_model = xgb.XGBRegressor(**params)\n",
    "    xgb_model.fit(X_train, y_train, \n",
    "                  eval_set=[(X_test, y_test)], \n",
    "                  verbose=True)\n",
    "    \n",
    "    y_pred_scaled = xgb_model.predict(X_test)\n",
    "\n",
    "    # 反标准化预测值和实际值\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_test_orig = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test_orig, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(y_test_orig, y_pred)\n",
    "    mae = mean_absolute_error(y_test_orig, y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    \n",
    "    mlflow.sklearn.log_model(xgb_model, \"model\")\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "print(f\"Test MSE: {mse}\")\n",
    "print(f\"Test RMSE: {rmse}\")\n",
    "print(f\"Test R²: {r2}\")\n",
    "print(f\"Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/05 13:37:51 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '6630667914454b93b136148d9af3afdf', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/07/05 13:38:01 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/07/05 13:38:21 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgboost_pipeline.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('./DATA/exported_data4.csv')\n",
    "X = data.drop('取引価格（総額）', axis=1)\n",
    "Y = data['取引価格（総額）']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建OneHotEncoder和OrdinalEncoder\n",
    "# 设置sparse_output=False以返回稠密矩阵，如果XGBoost或StandardScaler处理稀疏矩阵有问题\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "ordinal_encoder = OrdinalEncoder()  # 用于整数编码\n",
    "\n",
    "# ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ohe', onehot_encoder, ['地区名']),  # 假设地区名需要独热编码\n",
    "        ('ordinal', ordinal_encoder, ['建物の構造'])  # 使用OrdinalEncoder替代LabelEncoder\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "# XGBoost回归模型\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror', n_estimators=3000, learning_rate=0.04,\n",
    "    max_depth=8, subsample=0.8, colsample_bytree=0.8, reg_alpha=0.1,\n",
    "    reg_lambda=0.1, verbosity=2, eval_metric=['rmse', 'mae']\n",
    ")\n",
    "\n",
    "# 整个管道，包括预处理和XGBoost模型\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('scaler', StandardScaler()),  # 假设还包含标准化\n",
    "    ('regressor', xgb_model)  # 更改标识符为'regressor'，因为这是一个回归模型\n",
    "])\n",
    "\n",
    "# 训练管道\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 保存训练好的管道\n",
    "joblib.dump(pipeline, 'xgboost_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m建築年数\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m建築年数\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 使用管道预测新数据的房价\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m predicted_price \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(new_data)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 打印预测结果\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m预测的房价：\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_price)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:580\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m     patch_function\u001b[38;5;241m.\u001b[39mcall(call_original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 580\u001b[0m     patch_function(call_original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    582\u001b[0m session\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msucceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m try_log_autologging_event(\n\u001b[1;32m    585\u001b[0m     AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_patch_function_success,\n\u001b[1;32m    586\u001b[0m     session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     kwargs,\n\u001b[1;32m    591\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlflow/sklearn/__init__.py:1674\u001b[0m, in \u001b[0;36m_autolog.<locals>.patched_predict\u001b[0;34m(original, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _AUTOLOGGING_METRICS_MANAGER\u001b[38;5;241m.\u001b[39mshould_log_post_training_metrics() \u001b[38;5;129;01mand\u001b[39;00m run_id:\n\u001b[1;32m   1672\u001b[0m     \u001b[38;5;66;03m# Avoid nested patch when nested inference calls happens.\u001b[39;00m\n\u001b[1;32m   1673\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _AUTOLOGGING_METRICS_MANAGER\u001b[38;5;241m.\u001b[39mdisable_log_post_training_metrics():\n\u001b[0;32m-> 1674\u001b[0m         predict_result \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1675\u001b[0m     eval_dataset \u001b[38;5;241m=\u001b[39m get_instance_method_first_arg_value(original, args, kwargs)\n\u001b[1;32m   1676\u001b[0m     eval_dataset_name \u001b[38;5;241m=\u001b[39m _AUTOLOGGING_METRICS_MANAGER\u001b[38;5;241m.\u001b[39mregister_prediction_input_dataset(\n\u001b[1;32m   1677\u001b[0m         \u001b[38;5;28mself\u001b[39m, eval_dataset\n\u001b[1;32m   1678\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:561\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[0;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m         original_result \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;241m*\u001b[39m_og_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_og_kwargs)\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:496\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[0;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    489\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_start,\n\u001b[1;32m    490\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m         og_kwargs,\n\u001b[1;32m    495\u001b[0m     )\n\u001b[0;32m--> 496\u001b[0m     original_fn_result \u001b[38;5;241m=\u001b[39m original_fn(\u001b[38;5;241m*\u001b[39mog_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mog_kwargs)\n\u001b[1;32m    498\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    499\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_success,\n\u001b[1;32m    500\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m         og_kwargs,\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:558\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[0;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[1;32m    555\u001b[0m     disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    556\u001b[0m     reroute_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    557\u001b[0m ):\n\u001b[0;32m--> 558\u001b[0m     original_result \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;241m*\u001b[39m_og_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_og_kwargs)\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:480\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    478\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 480\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:800\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 800\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(\n\u001b[1;32m    801\u001b[0m     X,\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    803\u001b[0m     _transform_one,\n\u001b[1;32m    804\u001b[0m     fitted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    805\u001b[0m     column_as_strings\u001b[38;5;241m=\u001b[39mfit_dataframe_and_transform_dataframe,\n\u001b[1;32m    806\u001b[0m )\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:658\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    652\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[1;32m    654\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    655\u001b[0m     )\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[1;32m    659\u001b[0m         delayed(func)(\n\u001b[1;32m    660\u001b[0m             transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m    661\u001b[0m             X\u001b[38;5;241m=\u001b[39m_safe_indexing(X, column, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    662\u001b[0m             y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    663\u001b[0m             weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[1;32m    664\u001b[0m             message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    665\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(name, idx, \u001b[38;5;28mlen\u001b[39m(transformers)),\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transformers, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    668\u001b[0m     )\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:876\u001b[0m, in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m--> 876\u001b[0m     res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:1378\u001b[0m, in \u001b[0;36mOrdinalEncoder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;124;03m    Transform X to ordinal codes.\u001b[39;00m\n\u001b[1;32m   1367\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;124;03m        Transformed input.\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1378\u001b[0m     X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(\n\u001b[1;32m   1379\u001b[0m         X, handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1380\u001b[0m     )\n\u001b[1;32m   1381\u001b[0m     X_trans \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cat_idx, missing_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_missing_indices\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:166\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_features):\n\u001b[1;32m    165\u001b[0m     Xi \u001b[38;5;241m=\u001b[39m X_list[i]\n\u001b[0;32m--> 166\u001b[0m     diff, valid_mask \u001b[38;5;241m=\u001b[39m _check_unknown(Xi, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories_[i], return_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(valid_mask):\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:303\u001b[0m, in \u001b[0;36m_check_unknown\u001b[0;34m(values, known_values, return_mask)\u001b[0m\n\u001b[1;32m    300\u001b[0m         valid_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(values), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# check for nans in the known_values\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(known_values)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    304\u001b[0m     diff_is_nan \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(diff)\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff_is_nan\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;66;03m# removes nan from valid_mask\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# 加载训练好的管道\n",
    "pipeline = joblib.load('xgboost_pipeline.pkl')\n",
    "\n",
    "# 准备新的数据\n",
    "new_data = pd.DataFrame({\n",
    "    '最寄駅：距離（分）': [18],\n",
    "    '面積（㎡）': [100],\n",
    "    '建物の構造': [10],  # 确保这是数值类型，如果原始数据中这是字符串类型，可能需要转换\n",
    "    '建ぺい率（％）': [50],\n",
    "    '容積率（％）': [200],\n",
    "    '建築年数': [5],\n",
    "    '地区名': ['西蒲田']  # 假设这是一个分类特征，并已经通过OneHotEncoder进行处理\n",
    "})\n",
    "\n",
    "# 确保所有数值列都是正确的数据类型\n",
    "new_data['最寄駅：距離（分）'] = new_data['最寄駅：距離（分）'].astype(float)\n",
    "new_data['面積（㎡）'] = new_data['面積（㎡）'].astype(float)\n",
    "new_data['建物の構造'] = new_data['建物の構造'].astype(int)\n",
    "new_data['建ぺい率（％）'] = new_data['建ぺい率（％）'].astype(float)\n",
    "new_data['容積率（％）'] = new_data['容積率（％）'].astype(float)\n",
    "new_data['建築年数'] = new_data['建築年数'].astype(int)\n",
    "\n",
    "# 使用管道预测新数据的房价\n",
    "predicted_price = pipeline.predict(new_data)\n",
    "\n",
    "# 打印预测结果\n",
    "print(\"预测的房价：\", predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/05 13:51:53 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '20a717ffcf7b475d955b8a28ffb829b7', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据类型:\n",
      " 最寄駅：距離（分）      int64\n",
      "取引価格（総額）       int64\n",
      "面積（㎡）          int64\n",
      "建物の構造         object\n",
      "地区名           object\n",
      "建ぺい率（％）      float64\n",
      "容積率（％）       float64\n",
      "建築年数           int64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/05 13:51:58 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/07/05 13:52:04 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/07/05 13:52:07 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测价格： [30405978. 44360416. 58980780. ... 63497484. 32699766. 66778776.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('./DATA/exported_data4.csv')\n",
    "\n",
    "# 检查数据类型，确保每列都是正确的类型\n",
    "print(\"原始数据类型:\\n\", data.dtypes)\n",
    "\n",
    "# 将建物の構造列转换为数值型，如果是字符串\n",
    "data['建物の構造'] = pd.to_numeric(data['建物の構造'], errors='coerce')\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X = data.drop('取引価格（総額）', axis=1)\n",
    "Y = data['取引価格（総額）']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建预处理器\n",
    "# 对分类变量使用OneHotEncoder，对数值变量使用StandardScaler\n",
    "categorical_features = ['地区名']  # 假设地区名为分类变量\n",
    "numeric_features = [col for col in X.columns if col not in categorical_features and col != '建物の構造']  # 其他数值变量\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),  # 处理数值列的NaN值\n",
    "            ('scaler', StandardScaler())]), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('ord', OrdinalEncoder(), ['建物の構造'])  # 假设建物の構造为有序分类变量\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "# 创建XGBoost回归模型\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.04,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    verbosity=2,\n",
    "    eval_metric=['rmse', 'mae']\n",
    ")\n",
    "\n",
    "# 构建整个管道\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb_model)\n",
    "])\n",
    "\n",
    "# 训练管道\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 保存训练好的管道\n",
    "joblib.dump(pipeline, 'xgboost_pipeline.pkl')\n",
    "\n",
    "# 加载模型并进行预测（示例）\n",
    "loaded_pipeline = joblib.load('xgboost_pipeline.pkl')\n",
    "predicted_price = loaded_pipeline.predict(X_test)\n",
    "print(\"预测价格：\", predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/05 14:02:35 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '06a23bdaf02341849cbf45201864f05a', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/07/05 14:02:45 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/07/05 14:02:51 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/07/05 14:02:55 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测价格： [30482450. 44405860. 59131508. ... 62750568. 32472214. 65832696.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('./DATA/exported_data4.csv')\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X = data.drop('取引価格（総額）', axis=1)\n",
    "Y = data['取引価格（総額）']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建预处理器\n",
    "categorical_features = ['地区名']  # 假设地区名为分类变量\n",
    "numeric_features = [col for col in X.columns if col not in categorical_features and col != '建物の構造']  # 其他数值变量\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),  # 处理数值列的NaN值\n",
    "            ('scaler', StandardScaler())]), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('ord', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), ['建物の構造'])  # 使用use_encoded_value并指定unknown_value\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "# 创建XGBoost回归模型\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.04,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    verbosity=1,\n",
    "    eval_metric=['rmse', 'mae']\n",
    ")\n",
    "\n",
    "# 构建整个管道\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb_model)\n",
    "])\n",
    "\n",
    "# 训练管道\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 保存训练好的管道\n",
    "joblib.dump(pipeline, 'xgboost_pipeline.pkl')\n",
    "\n",
    "# 加载模型并进行预测（示例）\n",
    "loaded_pipeline = joblib.load('xgboost_pipeline.pkl')\n",
    "predicted_price = loaded_pipeline.predict(X_test)\n",
    "print(\"预测价格：\", predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('./DATA/exported_data4.csv')\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X = data.drop('取引価格（総額）', axis=1)\n",
    "Y = data['取引価格（総額）']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建预处理器\n",
    "categorical_features = ['地区名']  # 假设地区名为分类变量\n",
    "numeric_features = [col for col in X.columns if col not in categorical_features and col != '建物の構造']  # 其他数值变量\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),  # 处理数值列的NaN值\n",
    "            ('scaler', StandardScaler())]), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('ord', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), ['建物の構造'])  # 使用use_encoded_value并指定unknown_value\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "# 创建XGBoost回归模型\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.04,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    verbosity=1,\n",
    "    eval_metric=['rmse', 'mae']\n",
    ")\n",
    "\n",
    "# 构建整个管道\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb_model)\n",
    "])\n",
    "\n",
    "# 训练管道\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 保存训练好的管道\n",
    "joblib.dump(pipeline, 'xgboost_pipeline.pkl')\n",
    "\n",
    "# 加载模型并进行预测（示例）\n",
    "loaded_pipeline = joblib.load('xgboost_pipeline.pkl')\n",
    "predicted_price = loaded_pipeline.predict(X_test)\n",
    "print(\"预测价格：\", predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('./DATA/exported_data4.csv')\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X = data.drop('取引価格（総額）', axis=1)\n",
    "Y = data['取引価格（総額）']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建预处理器\n",
    "categorical_features = ['地区名']  # 假设地区名为分类变量\n",
    "numeric_features = [col for col in X.columns if col not in categorical_features and col != '建物の構造']  # 其他数值变量\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),  # 处理数值列的NaN值\n",
    "            ('scaler', StandardScaler())]), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('ord', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), ['建物の構造'])  # 使用use_encoded_value并指定unknown_value\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "# 创建XGBoost回归模型\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.04,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    verbosity=1,\n",
    "    eval_metric=['rmse', 'mae']\n",
    ")\n",
    "\n",
    "# 构建整个管道\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb_model)\n",
    "])\n",
    "\n",
    "# 训练管道\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 保存训练好的管道\n",
    "joblib.dump(pipeline, 'xgboost_pipeline.pkl')\n",
    "\n",
    "# 加载模型并进行预测（示例）\n",
    "loaded_pipeline = joblib.load('xgboost_pipeline.pkl')\n",
    "predicted_price = loaded_pipeline.predict(X_test)\n",
    "print(\"预测价格：\", predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "\n",
    "# 启动 MLflow\n",
    "mlflow.set_experiment(\"XGBoost_Regression\")\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('./DATA/exported_data4.csv')\n",
    "X = data.drop('取引価格（総額）', axis=1)\n",
    "Y = data['取引価格（総額）']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建预处理器\n",
    "categorical_features = ['地区名']  # 假设地区名为分类变量\n",
    "numeric_features = [col for col in X.columns if col not in categorical_features and col != '建物の構造']  # 其他数值变量\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),  # 处理数值列的NaN值\n",
    "            ('scaler', StandardScaler())]), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('ord', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), ['建物の構造'])\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "# 创建XGBoost回归模型\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=4000,\n",
    "    learning_rate=0.06,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.2,\n",
    "    reg_lambda=0.2,\n",
    "    verbosity=1,\n",
    "    eval_metric=['rmse', 'mae']\n",
    ")\n",
    "\n",
    "# 构建整个管道\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb_model)\n",
    "])\n",
    "\n",
    "# 定义运行的名字\n",
    "run_name = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\") + \"_xgboost\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    # 训练管道\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # 评估模型\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    # 打印指标\n",
    "    print(\"MSE:\", mse)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"MAE:\", mae)\n",
    "    print(\"R2 Score:\", r2)\n",
    "    \n",
    "    # 记录指标\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    \n",
    "    # 记录模型\n",
    "    mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "    \n",
    "    # 保存训练好的管道\n",
    "    joblib.dump(pipeline, 'xgboost_pipeline.pkl')\n",
    "\n",
    "# 加载模型并进行预测（示例）\n",
    "loaded_pipeline = joblib.load('xgboost_pipeline.pkl')\n",
    "predicted_price = loaded_pipeline.predict(X_test)\n",
    "print(\"预测价格：\", predicted_price)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
